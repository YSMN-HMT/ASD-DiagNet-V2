import keras

if p_Method=="ASD-DiagNet":
    eig_data = {}
    
    for f in flist:  
        d = get_corr_matrix(f)
        eig_vals, eig_vecs = np.linalg.eig(d)

        for ev in eig_vecs.T:
          np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))

        sum_eigvals = np.sum(np.abs(eig_vals))
        # Make a list of (eigenvalue, eigenvector, norm_eigval) tuples
        eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i], np.abs(eig_vals[i])/sum_eigvals)
                     for i in range(len(eig_vals))]

        # Sort the (eigenvalue, eigenvector) tuples from high to low
        eig_pairs.sort(key=lambda x: x[0], reverse=True)

        eig_data[f] = {'eigvals':np.array([ep[0] for ep in eig_pairs]),
                       'norm-eigvals':np.array([ep[2] for ep in eig_pairs]),
                       'eigvecs':[ep[1] for ep in eig_pairs]}

#**********************************************************
# Prepare the dataset for test and train
#**********************************************************

class CCTOTAL(keras.utils.all_utils.Sequence):
    def __init__(self,pkl_filename=None, data = None, samples_list=None,
                 augmentation=False, aug_factor=1, num_neighbs=5 ,
                 eig_data = None, similarity_fn = None, verbose = False,regs = None):
      
        self.regs = regs

      if pkl_filename is not None:
        if verbose:
          print('Loading ..!', end=' ')
        self.data = pickle.load(open(pkl_filename, 'rb'))  
      elif data is not None:
        self.data = data.copy()
      else:
          sys.stderr.write('Eigther PKL file or data is needed!')
          return
        
      if samples_list is None:
        self.flist = [f for f in self.data]
      else:
        self.flist = [f for f in samples_list]

      self.labels = np.array([self.data[f][1] for f in self.flist])

      current_flist = np.array(self.flist.copy())
      current_lab0_flist = current_flist[self.labels == 0]
      current_lab1_flist = current_flist[self.labels == 1]

      if augmentation:
          self.num_data = aug_factor * len(self.flist)
          self.neighbors = {}
          weights = norm_weights(samples_list)
          for f in self.flist:
              label = self.data[f][1]
              candidates = (set(current_lab0_flist) if label == 0 else set(current_lab1_flist))
              candidates.remove(f)
              eig_f = eig_data[f]['eigvecs']
              sim_list = []
              for cand in candidates:
                  eig_cand = eig_data[cand]['eigvecs']
                  sim = similarity_fn(eig_f, eig_cand,weights)
                  sim_list.append((sim, cand))
              sim_list.sort (key=lambda x: x[0], reverse=True)
              self.neighbors[f] = [item[1] for item in sim_list[:num_neighbs]]
          self.num_data = len(self.flist)
    
    def __len__(self):
      return self.num_data

    def __getitem__(self, index):
      if index < len(self.flist):
        fname = self.flist[index]
        data = self.data[fname][0].copy()  
        data = data[self.regs].copy()
        label = (self.labels[index],)
        return np.asarray(data).astype('float64') , np.asarray(label).astype('float64')
      else:
        f1 = self.flist[index % len(self.flist)]
        d1, y1 = self.data[f1][0], self.data[f1][1]
        d1 = d1[self.regs]
        f2 = np.random.choice(self.neighbors[f1])
        d2, y2 = self.data[f2][0], self.data[f2][1]
        d2 = d2[self.regs]
        assert y1 == y2
        r = np.random.uniform(low=0, high=1)
        label = (y1,)
        data = r * d1 + (1 - r) * d2
        return np.asarray(data).astype('float64') , np.asarray(label).astype('float64')    