#*********************************************************
# Assign each data to its label. 
#*********************************************************

def getdata(train_loader = None , batch_size = 8 , mode = 'Train' ):

  # pdb.set_trace()
  ii = int(len(train_loader)/ batch_size)

  if mode == 'Train':
        indexes = np.arange(len(train_loader))
        random.shuffle(indexes)
  else :
    indexes = np.arange(len(train_loader))
    
  data = np.empty((ii,batch_size , 9950), dtype=float) 

  label = np.empty((ii,batch_size , 1), dtype=float)
  for n in range(ii): #number of batches
    
      index = indexes[n*batch_size:(n+1)*batch_size]
      data[n,] = np.array([train_loader[k][0] for k in index])
      label[n,] = np.array([train_loader[k][1] for k in index])
  return data , label

#*********************************************************
# Train function
#*********************************************************

def train(model,train_dataset1, epochs ,batch_size , p_bernoulli=None, mode='both', lam_factor=1.0):  
    optimizer  = optimizers.SGD(lr = 0.0001, momentum = 0.9)
	
    train_losses = []
    for epoch in range(epochs): 
      print("\nStart of epoch %d" % (epoch,))
      for index in range(len(train_dataset1[1])): #247 batches OR :  for index , x in enumerate(train_dataset1)
        if len(train_dataset1[0][index]) != batch_size:
          continue    
        if p_bernoulli is not None:
          if index == 0:
            p_tensor = tf.keras.backend.ones_like(train_dataset1[0][index])*p_bernoulli
          rand_bernoulli = tf.keras.backend.random_bernoulli(shape = k.int_shape(p_tensor),p=p_tensor)
        
        data, target = train_dataset1[0][index] ,train_dataset1[1][index]
        # pdb.set_trace()
        with tf.GradientTape() as tape:
          if mode in ['both', 'ae']:
            if p_bernoulli is not None:
              rec_noisy, _ = model(data * rand_bernoulli,False)
              loss_ae = criterion_ae(data,rec_noisy) / len(train_dataset1[0][index])
            else:
              rec, _ = model(data, False)
              loss_ae = criterion_ae(data,rec) / len(train_dataset1[0][index])

          if mode in ['both', 'clf']:
            rec_clean, logits = model(data, True)
            loss_clf = criterion_clf(target,logits)
          
          if mode == 'both':
            loss_total = loss_ae + lam_factor * loss_clf
            train_losses.append([loss_ae.numpy(),loss_clf.numpy()])
          
          elif mode == 'ae':
            loss_total = loss_ae
            train_losses.append([loss_ae.numpy(),0.0])
          
          elif mode == 'clf':
            loss_total = loss_clf
            train_losses.append([0.0,loss_clf.numpy()])

        grads = tape.gradient(loss_total, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights)) 
        
        if index % 100 == 0:
            print(
                "Training at step %d:"
                % index)
            print("total loss avg:")
            print(np.mean(np.array(loss_total),axis = 0))
        
    return train_losses

#*********************************************************
# Test function
#*********************************************************

def test(model, test_dataset1,
         eval_classifier=False, num_batch=None):
 
      test_loss, n_test, correct = 0.0, 0, 0
      all_predss=[]      
      mse = keras.losses.MeanSquaredError(reduction = "sum_over_batch_size")
	  
      if eval_classifier:
        y_true, y_pred = [], []  
      
      for i in range(1,(len(test_dataset1[1])+1)):
        if num_batch is not None:
            if i >= num_batch:
                continue
				
        data = test_dataset1[0][i-1]
        rec, logits = model(data, eval_classifier)
        test_loss += mse(data,rec).numpy() 
        n_test += len(test_dataset1[0][i-1])

        if eval_classifier:
            preds = np.ones_like(logits, dtype = np.int32)
            preds[logits.numpy() < 0.5] = 0
            all_predss.extend(preds)
            y_arr = test_dataset1[1][i-1]
            correct += np.sum(preds == y_arr)
            y_true.extend(y_arr.tolist())
            y_pred.extend(logits)#.tolist())
			
        mlp_acc, mlp_sens, mlp_spef = confusion(y_true, all_predss)

      return mlp_acc, mlp_sens, mlp_spef  # ,correct/n_test
 